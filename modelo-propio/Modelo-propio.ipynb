{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación del algoritmo de detección basado en un autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de librerías externas, nombre del archivo con espectros de entrenamiento y número de archivos de recolección de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample, randrange\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, f1_score\n",
    "from keras.layers import Dense, Dropout, Normalization, LSTM, TimeDistributed, RepeatVector\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'coef_adev': 1,\n",
    "    },\n",
    "    {\n",
    "        'coef_adev': 2,\n",
    "    },\n",
    "    {\n",
    "        'coef_adev': 3,\n",
    "    },\n",
    "    {\n",
    "        'coef_adev': 4,\n",
    "    },\n",
    "    {\n",
    "        'coef_adev': 5,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Posición más alta del vector que actúa como eje X\n",
    "max_x = 1024\n",
    "\n",
    "archivo_entrenamiento = '../resultados_entrenamiento.ndjson'\n",
    "ruta_guardado_modelo = './modelo_entrenado'\n",
    "\n",
    "numero_archivos_inferencia = 10\n",
    "\n",
    "config_modelo_propio = {\n",
    "    'pasos_por_muestra': 256,\n",
    "    'tasa_dropout': 0.2,\n",
    "    'epochs': 500,\n",
    "    'batch_size': 32,\n",
    "    'proporcion_conjunto_prueba': 0.1,\n",
    "    'proporcion_validacion': 0.1,\n",
    "    'min_delta_early_stopping': 0.001,\n",
    "    'paciencia_early_stopping': 10,\n",
    "    'cargar_modelo': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones de carga de espectros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserializar_espectro(espectro):\n",
    "    espectro['vector_base'] = np.array(espectro['vector_base'])\n",
    "    espectro['espectro_base_muestra'] = np.array(espectro['espectro_base_muestra'])\n",
    "    espectro['espectro_base_background'] = np.array(espectro['espectro_base_background'])\n",
    "    espectro['baseline_muestra'] = np.array(espectro['baseline_muestra'])\n",
    "    espectro['baseline_background'] = np.array(espectro['baseline_background'])\n",
    "    espectro['muestra_con_baseline'] = np.array(espectro['muestra_con_baseline'])\n",
    "    espectro['background_con_baseline'] = np.array(espectro['background_con_baseline'])\n",
    "    espectro['muestra_combinado_base'] = np.array(espectro['muestra_combinado_base'])\n",
    "    espectro['espectro_ruido_combinado'] = np.array(espectro['espectro_ruido_combinado'])\n",
    "    espectro['espectro_ruido_background'] = np.array(espectro['espectro_ruido_background'])\n",
    "    espectro['spikes_muestra'] = np.array(espectro['spikes_muestra'])\n",
    "    espectro['spikes_background'] = np.array(espectro['spikes_background'])\n",
    "    espectro['flag_spikes_muestra'] = np.array(espectro['flag_spikes_muestra'])\n",
    "    espectro['flag_spikes_background'] = np.array(espectro['flag_spikes_background'])\n",
    "    espectro['muestra_base_con_spikes'] = np.array(espectro['muestra_base_con_spikes'])\n",
    "    espectro['y_muestra'] = np.array(espectro['y_muestra'])\n",
    "    espectro['y_background'] = np.array(espectro['y_background'])\n",
    "\n",
    "    return espectro\n",
    "\n",
    "def cargar_espectros(nombre_archivo):\n",
    "    with open(nombre_archivo, 'r') as fp:\n",
    "        data = []\n",
    "        for line in fp:\n",
    "            data.append(deserializar_espectro(json.loads(line)))\n",
    "        fp.close()\n",
    "        return data\n",
    "\n",
    "espectros = cargar_espectros(archivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para calcular métricas de clasificación de spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_clasificacion(valores_reales, predicciones):\n",
    "    _predicciones = np.array(predicciones).flatten()\n",
    "    _valores_reales = np.array(valores_reales).flatten()\n",
    "\n",
    "    return precision_recall_fscore_support(_valores_reales, _predicciones), confusion_matrix(_valores_reales, _predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación del conjunto de datos en conjuntos de prueba y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "espectros_entrenamiento, espectros_prueba = train_test_split(espectros, test_size=config_modelo_propio['proporcion_conjunto_prueba'])\n",
    "\n",
    "etiquetas_entrenamiento = [espectro['spikes_muestra'] for espectro in espectros_entrenamiento]\n",
    "etiquetas_prueba = [espectro['spikes_muestra'] for espectro in espectros_prueba]\n",
    "\n",
    "muestras_ruido_multiple_entrenamiento = [espectro['muestra_base_con_spikes'] for espectro in espectros_entrenamiento]\n",
    "muestras_ruido_multiple_prueba = [espectro['muestra_base_con_spikes'] for espectro in espectros_prueba]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación de un algoritmo basado en un denoising autoencoder para detección de spikes, así como funciones auxiliares para recogida de datos y visualización de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_compatible_lstm(x, y, pasos_por_muestra):\n",
    "    x_compatible = np.array(x)\n",
    "    x_compatible = x_compatible.reshape(\n",
    "        (x_compatible.shape[0], pasos_por_muestra, round(x_compatible.shape[1] / pasos_por_muestra))\n",
    "    )\n",
    "    \n",
    "    y_compatible = np.array(y)\n",
    "    y_compatible = y_compatible.reshape(\n",
    "        (y_compatible.shape[0], pasos_por_muestra, round(y_compatible.shape[1] / pasos_por_muestra))\n",
    "    )\n",
    "    \n",
    "    return x_compatible, y_compatible\n",
    "\n",
    "def crear_modelo_propio_entrenado(X_entrenamiento, config_modelo):\n",
    "    ventana = config_modelo['pasos_por_muestra']\n",
    "    tasa_dropout = config_modelo['tasa_dropout']\n",
    "    epochs = config_modelo['epochs']\n",
    "    batch_size = config_modelo['batch_size']\n",
    "    min_delta = config_modelo['min_delta_early_stopping']\n",
    "    paciencia = config_modelo['paciencia_early_stopping']\n",
    "    proporcion_validacion = config_modelo['proporcion_validacion']\n",
    "    \n",
    "    X, _ = transformar_compatible_lstm(\n",
    "        X_entrenamiento,\n",
    "        X_entrenamiento,\n",
    "        ventana\n",
    "    )\n",
    "\n",
    "    shape = X.shape\n",
    "    modelo = Sequential()\n",
    "    normalizador = Normalization(input_shape=(shape[1], shape[2]))\n",
    "\n",
    "    normalizador.adapt(X)\n",
    "\n",
    "    modelo.add(normalizador)\n",
    "\n",
    "    modelo.add(LSTM(ventana))\n",
    "    modelo.add(Dropout(rate=tasa_dropout))\n",
    "\n",
    "    modelo.add(RepeatVector(shape[1]))\n",
    "\n",
    "    modelo.add(LSTM(ventana, return_sequences=True))\n",
    "    modelo.add(TimeDistributed(Dense(shape[2])))\n",
    "    modelo.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    modelo.summary()\n",
    "\n",
    "    callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=min_delta,\n",
    "        patience=paciencia,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    \n",
    "    historia = modelo.fit(\n",
    "        X,\n",
    "        X,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=proporcion_validacion,\n",
    "        verbose=1,\n",
    "        callbacks=[callback]\n",
    "    )\n",
    "    \n",
    "    return modelo, historia\n",
    "\n",
    "def realizar_inferencia_modelo_propio(modelo_entrenado, X, config_modelo, coef_adev = 3):\n",
    "    ventana = config_modelo['pasos_por_muestra']\n",
    "    X, _ = transformar_compatible_lstm(\n",
    "        X,\n",
    "        X,\n",
    "        ventana\n",
    "    )\n",
    "    \n",
    "    prediccion_cruda = modelo_entrenado.predict(X)\n",
    "    \n",
    "    detecciones = []\n",
    "    predicciones = []\n",
    "    residuales = []\n",
    "    umbrales_adev = []\n",
    "        \n",
    "    for i in range(len(X)):\n",
    "        datos_originales = X[i].flatten()\n",
    "        prediccion = prediccion_cruda[i].flatten()\n",
    "        \n",
    "        serie = datos_originales - prediccion\n",
    "        \n",
    "        serie_diferenciada = np.diff(serie)\n",
    "        \n",
    "        segunda_diferencia = np.diff(serie_diferenciada)\n",
    "        suma_segundas_diferencias_cuadrado = np.sum(segunda_diferencia ** 2)\n",
    "        adev = math.sqrt(suma_segundas_diferencias_cuadrado / (2 * (len(segunda_diferencia) - 2)))\n",
    "                \n",
    "        umbral_adev = coef_adev * adev\n",
    "\n",
    "        deteccion = np.abs(serie_diferenciada) > umbral_adev\n",
    "        \n",
    "        deteccion = np.insert(deteccion, 0, False)\n",
    "                \n",
    "        detecciones.append(deteccion)\n",
    "        predicciones.append(prediccion)\n",
    "        residuales.append(serie_diferenciada)\n",
    "        umbrales_adev.append(umbral_adev)\n",
    "            \n",
    "    return detecciones, predicciones, residuales, umbrales_adev\n",
    "\n",
    "def obtener_resultado_modelo_propio(modelo_entrenado, X, y, config_modelo, coef_adev = 3):\n",
    "    predicciones, _, _, _ = realizar_inferencia_modelo_propio(\n",
    "        modelo_entrenado,\n",
    "        X,\n",
    "        config_modelo,\n",
    "        coef_adev\n",
    "    )\n",
    "    \n",
    "    return predicciones, calcular_metricas_clasificacion(y, predicciones)\n",
    "\n",
    "def visualizar_resultado_modelo_propio(vector_base, modelo_entrenado, X, etiquetas, config_modelo, coef_adev = 3):\n",
    "    predicciones, forma, residuales, umbrales_adev = realizar_inferencia_modelo_propio(\n",
    "        modelo_entrenado,\n",
    "        X,\n",
    "        config_modelo,\n",
    "        coef_adev\n",
    "    )\n",
    "    \n",
    "    predicciones = predicciones[0]\n",
    "    forma = forma[0]\n",
    "    residuales = residuales[0]\n",
    "    umbral_adev = umbrales_adev[0]\n",
    "    \n",
    "    fig = plt.figure(figsize=[45, 15], constrained_layout=True)\n",
    "\n",
    "    fig.suptitle(\"Muestra de resultados al aplicar el algoritmo propio\", fontsize=24, fontweight='bold')\n",
    "\n",
    "    subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "\n",
    "    for row, subfig in enumerate(subfigs):\n",
    "        (ax) = subfig.subplots(nrows=1, ncols=1)\n",
    "\n",
    "        if row == 0:\n",
    "            ax.set_title(\"Serie original\", fontsize=18)\n",
    "            ax.plot(vector_base, X[0], label=\"Serie original\")\n",
    "            ax.plot(vector_base, forma, label=\"Serie reconstruida por el modelo\", c='r')\n",
    "            ax.legend(fontsize=28)\n",
    "        elif row == 1:\n",
    "            ax.set_title(\"Serie de valores residuales y umbral\", fontsize=18)\n",
    "            residuales = np.insert(residuales, 0, 0)\n",
    "            ax.plot(vector_base, residuales)\n",
    "            plt.axhline(y = umbral_adev, color = 'r', linestyle = '-')\n",
    "            plt.axhline(y = -umbral_adev, color = 'r', linestyle = '-')\n",
    "        elif row == 2:\n",
    "            categorias = {\n",
    "                'tp': {\n",
    "                    'color': 'blue',\n",
    "                    'label': 'Detecciones'\n",
    "                },\n",
    "                'fp': {\n",
    "                    'color': 'black',\n",
    "                    'label': 'Falsos positivos'\n",
    "                },\n",
    "                'fn': {\n",
    "                    'color': 'red',\n",
    "                    'label': 'Falsos negativos'\n",
    "                }\n",
    "            }\n",
    "\n",
    "            detecciones_agrupadas = []\n",
    "\n",
    "            for i, es_resultado in enumerate(predicciones):\n",
    "                label = ''\n",
    "                es_spike = etiquetas[i]\n",
    "\n",
    "                if es_spike:\n",
    "                    if es_resultado:\n",
    "                        label = 'tp'\n",
    "                    else:\n",
    "                        label = 'fn'\n",
    "                elif es_resultado:\n",
    "                    label = 'fp'\n",
    "                else:\n",
    "                    label = 'tn'\n",
    "                detecciones_agrupadas.append(label)\n",
    "\n",
    "            detecciones_agrupadas = np.array(detecciones_agrupadas)\n",
    "\n",
    "            ax.set_title(\"Serie con spikes detectados y tipos de detección\", fontsize=18)\n",
    "            ax.plot(vector_base, X[0])\n",
    "            ax.scatter(vector_base[detecciones_agrupadas == 'tp'], X[0][detecciones_agrupadas == 'tp'], c=categorias['tp']['color'], label=categorias['tp']['label'], s=100)\n",
    "            ax.scatter(vector_base[detecciones_agrupadas == 'fp'], X[0][detecciones_agrupadas == 'fp'], c=categorias['fp']['color'], label=categorias['fp']['label'], s=100)\n",
    "            ax.scatter(vector_base[detecciones_agrupadas == 'fn'], X[0][detecciones_agrupadas == 'fn'], c=categorias['fn']['color'], label=categorias['fn']['label'], s=100)\n",
    "\n",
    "            ax.legend(fontsize=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_propio_entrenado = None\n",
    "historial_entrenamiento = None\n",
    "\n",
    "if config_modelo_propio['cargar_modelo']:\n",
    "    modelo_propio_entrenado = tf.keras.models.load_model(ruta_guardado_modelo)\n",
    "else:\n",
    "    modelo_propio_entrenado, historial_entrenamiento = crear_modelo_propio_entrenado(\n",
    "        muestras_ruido_multiple_entrenamiento,\n",
    "        config_modelo_propio\n",
    "    )\n",
    "\n",
    "    modelo_propio_entrenado.save(ruta_guardado_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba del modelo entrenado, para detectar posible overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prueba, y_prueba = transformar_compatible_lstm(\n",
    "    muestras_ruido_multiple_prueba,\n",
    "    etiquetas_prueba,\n",
    "    config_modelo_propio['pasos_por_muestra'],\n",
    ")\n",
    "\n",
    "if not config_modelo_propio['cargar_modelo']:\n",
    "    resultado_evaluacion_modelo = modelo_propio_entrenado.evaluate(X_prueba, y_prueba, verbose=2)\n",
    "    with open('historial_entrenamiento_modelo_propio', 'wb') as fp:\n",
    "        pickle.dump({\n",
    "            'historial_entrenamiento': historial_entrenamiento,\n",
    "            'validacion': resultado_evaluacion_modelo\n",
    "        }, fp)\n",
    "        fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recogida de datos y guardado de los resultados en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_modelo_propio_ruido = []\n",
    "resultados_modelo_propio_sin_ruido = []\n",
    "\n",
    "def procesar_archivo(n):\n",
    "    nombre_archivo = '../resultados_' + str(n) + '.ndjson'\n",
    "\n",
    "    resultados_ruido = []\n",
    "    resultados_sin_ruido = []\n",
    "\n",
    "    espectros = cargar_espectros(nombre_archivo)\n",
    "\n",
    "    espectros_base_con_spikes_con_ruido = []\n",
    "    espectros_base_con_spikes_sin_ruido = []\n",
    "    etiquetas = []\n",
    "\n",
    "    for espectro in espectros:\n",
    "        espectros_base_con_spikes_con_ruido.append(espectro['muestra_base_con_spikes'])\n",
    "        espectros_base_con_spikes_sin_ruido.append(espectro['espectro_base_muestra'] + espectro['spikes_muestra'])\n",
    "        etiquetas.append(espectro['flag_spikes_muestra'])\n",
    "\n",
    "    predicciones_modelo_propio_ruido, metricas_modelo_propio_ruido = obtener_resultado_modelo_propio(\n",
    "        modelo_propio_entrenado,\n",
    "        espectros_base_con_spikes_con_ruido,\n",
    "        etiquetas,\n",
    "        config_modelo_propio,\n",
    "        coef_adev=param['coef_adev'],\n",
    "    )\n",
    "    predicciones_modelo_propio_sin_ruido, metricas_modelo_propio_sin_ruido = obtener_resultado_modelo_propio(\n",
    "        modelo_propio_entrenado,\n",
    "        espectros_base_con_spikes_sin_ruido,\n",
    "        etiquetas,\n",
    "        config_modelo_propio,\n",
    "        coef_adev=param['coef_adev'],\n",
    "    )\n",
    "\n",
    "    resultados_ruido.append({\n",
    "        'precision_negativos': metricas_modelo_propio_ruido[0][0][0],\n",
    "        'precision_positivos': metricas_modelo_propio_ruido[0][0][1],\n",
    "        'support_negativos': metricas_modelo_propio_ruido[0][1][0],\n",
    "        'support_positivos': metricas_modelo_propio_ruido[0][1][1],\n",
    "        'f1_negativos': metricas_modelo_propio_ruido[0][2][0],\n",
    "        'f1_positivos': metricas_modelo_propio_ruido[0][2][1],\n",
    "        'vn': metricas_modelo_propio_ruido[1][0][0],\n",
    "        'fp': metricas_modelo_propio_ruido[1][0][1],\n",
    "        'fn': metricas_modelo_propio_ruido[1][1][0],\n",
    "        'vp': metricas_modelo_propio_ruido[1][1][1]\n",
    "    })\n",
    "\n",
    "    resultados_sin_ruido.append({\n",
    "        'precision_negativos': metricas_modelo_propio_sin_ruido[0][0][0],\n",
    "        'precision_positivos': metricas_modelo_propio_sin_ruido[0][0][1],\n",
    "        'support_negativos': metricas_modelo_propio_sin_ruido[0][1][0],\n",
    "        'support_positivos': metricas_modelo_propio_sin_ruido[0][1][1],\n",
    "        'f1_negativos': metricas_modelo_propio_sin_ruido[0][2][0],\n",
    "        'f1_positivos': metricas_modelo_propio_sin_ruido[0][2][1],\n",
    "        'vn': metricas_modelo_propio_sin_ruido[1][0][0],\n",
    "        'fp': metricas_modelo_propio_sin_ruido[1][0][1],\n",
    "        'fn': metricas_modelo_propio_sin_ruido[1][1][0],\n",
    "        'vp': metricas_modelo_propio_sin_ruido[1][1][1]\n",
    "    })\n",
    "\n",
    "    return resultados_ruido, resultados_sin_ruido\n",
    "\n",
    "for param in params:\n",
    "    resultados_archivo = [procesar_archivo(n) for n in range(numero_archivos_inferencia)]\n",
    "\n",
    "    resultados_ruido = [resultado[0][0] for resultado in resultados_archivo]\n",
    "    resultados_sin_ruido = [resultado[1][0] for resultado in resultados_archivo]\n",
    "\n",
    "    resultados_modelo_propio_ruido.append({\n",
    "        'param': param,\n",
    "        'resultados': resultados_ruido\n",
    "    })\n",
    "\n",
    "    resultados_modelo_propio_sin_ruido.append({\n",
    "        'param': param,\n",
    "        'resultados': resultados_sin_ruido\n",
    "    })\n",
    "\n",
    "with open('resultados_modelo_propio_ruido', 'wb') as fp:\n",
    "    pickle.dump(resultados_modelo_propio_ruido, fp)\n",
    "    fp.close()\n",
    "\n",
    "with open('resultados_modelo_propio_sin_ruido', 'wb') as fp:\n",
    "    pickle.dump(resultados_modelo_propio_sin_ruido, fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí obtenemos y guardamos en un archivo los peores resultados obtenidos por el algoritmo con sus mejores parámetros (con o sin ruido) para posterior análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_medias_f1_positivos_ruido = [np.mean([resultado['f1_positivos'] for resultado in resultado_param['resultados']]) for resultado_param in resultados_modelo_propio_ruido]\n",
    "indice_mejores_params_ruido = np.argmax(lista_medias_f1_positivos_ruido)\n",
    "mejores_params_ruido = params[indice_mejores_params_ruido]\n",
    "\n",
    "lista_medias_f1_positivos_sin_ruido = [np.mean([resultado['f1_positivos'] for resultado in resultado_param['resultados']]) for resultado_param in resultados_modelo_propio_sin_ruido]\n",
    "indice_mejores_params_sin_ruido = np.argmax(lista_medias_f1_positivos_sin_ruido)\n",
    "mejores_params_sin_ruido = params[indice_mejores_params_sin_ruido]\n",
    "\n",
    "archivo_azar = randrange(numero_archivos_inferencia)\n",
    "\n",
    "nombre_archivo = '../resultados_' + str(archivo_azar) + '.ndjson'\n",
    "\n",
    "espectros = cargar_espectros(nombre_archivo)\n",
    "\n",
    "prediccion_con_ruido = realizar_inferencia_modelo_propio(\n",
    "    modelo_propio_entrenado,\n",
    "    [espectro['muestra_base_con_spikes'] for espectro in espectros],\n",
    "    config_modelo_propio,\n",
    "    coef_adev=mejores_params_ruido['coef_adev']\n",
    ")[0]\n",
    "\n",
    "prediccion_sin_ruido = realizar_inferencia_modelo_propio(\n",
    "    modelo_propio_entrenado,\n",
    "    [espectro['espectro_base_muestra'] + espectro['spikes_muestra'] for espectro in espectros],\n",
    "    config_modelo_propio,\n",
    "    coef_adev=mejores_params_sin_ruido['coef_adev']\n",
    ")[0]\n",
    "\n",
    "resultados_f1_ruido = [(\n",
    "    espectro['muestra_base_con_spikes'],\n",
    "    f1_score(\n",
    "        espectro['flag_spikes_muestra'],\n",
    "        prediccion_con_ruido[i],\n",
    "        zero_division=1\n",
    "    ),\n",
    "    prediccion_con_ruido[i],\n",
    "    espectro['flag_spikes_muestra'],\n",
    "    mejores_params_ruido\n",
    ") for i, espectro in enumerate(espectros)]\n",
    "\n",
    "resultados_f1_sin_ruido = [(\n",
    "    espectro['espectro_base_muestra'] + espectro['spikes_muestra'],\n",
    "    f1_score(\n",
    "        espectro['flag_spikes_muestra'],\n",
    "        prediccion_sin_ruido[i],\n",
    "        zero_division=1\n",
    "    ),\n",
    "    prediccion_sin_ruido[i],\n",
    "    espectro['flag_spikes_muestra'],\n",
    "    mejores_params_sin_ruido\n",
    ") for i, espectro in enumerate(espectros)]\n",
    "\n",
    "resultados_f1_ruido = list(filter(lambda d: d[1] > 0, resultados_f1_ruido))\n",
    "resultados_f1_sin_ruido = list(filter(lambda d: d[1] > 0, resultados_f1_sin_ruido))\n",
    "\n",
    "resultados_f1_ruido = sorted(resultados_f1_ruido, key=lambda d: d[1])\n",
    "resultados_f1_sin_ruido = sorted(resultados_f1_sin_ruido, key=lambda d: d[1])\n",
    "\n",
    "with open('peores_resultados_modelo_propio', 'wb') as fp:\n",
    "    peores_resultados_ruido = resultados_f1_ruido[0:10]\n",
    "    peores_resultados_sin_ruido = resultados_f1_sin_ruido[0:10]\n",
    "    peores_resultados = {\n",
    "        'ruido': peores_resultados_ruido,\n",
    "        'sin_ruido': peores_resultados_sin_ruido\n",
    "    }\n",
    "    pickle.dump(peores_resultados, fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toma de una muestra aleatoria de los resultados para control de calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_muestra = sample(list(range(len(espectros))), 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del resultado de la aplicación del algoritmo a un espectro aleatorio al que no le fue añadido ruido aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizar_resultado_modelo_propio(\n",
    "    espectros[indice_muestra]['vector_base'],\n",
    "    modelo_propio_entrenado,\n",
    "    [espectros[indice_muestra]['espectro_base_muestra'] + espectros[indice_muestra]['spikes_muestra']],\n",
    "    espectros[indice_muestra]['flag_spikes_muestra'],\n",
    "    config_modelo_propio,\n",
    "    coef_adev=mejores_params_sin_ruido['coef_adev']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del resultado de la aplicación del algoritmo a un espectro aleatorio al que le fue añadido ruido aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizar_resultado_modelo_propio(\n",
    "    espectros[indice_muestra]['vector_base'],\n",
    "    modelo_propio_entrenado,\n",
    "    [espectros[indice_muestra]['muestra_base_con_spikes']],\n",
    "    espectros[indice_muestra]['flag_spikes_muestra'],\n",
    "    config_modelo_propio,\n",
    "    coef_adev=mejores_params_sin_ruido['coef_adev']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
